# Download Retry & Resume Mechanism ğŸ”„

## âœ… Automatic Retry System

### **How Many Retries?**

**Total Attempts:** **5 tries** (1 initial + 4 automatic retries)

If a download fails due to network issues, server errors, or any other reason, the system automatically retries **4 more times** before marking it as permanently failed.

---

## ğŸ“Š Retry Timeline

```
Attempt 1: Download starts immediately
   â†“ (fails due to network error)
   
Attempt 2: Retry after 2 seconds â±ï¸
   â†“ (fails again)
   
Attempt 3: Retry after 4 seconds â±ï¸â±ï¸
   â†“ (fails again)
   
Attempt 4: Retry after 8 seconds â±ï¸â±ï¸â±ï¸â±ï¸
   â†“ (fails again)
   
Attempt 5: Retry after 16 seconds â±ï¸â±ï¸â±ï¸â±ï¸â±ï¸â±ï¸â±ï¸â±ï¸
   â†“ (fails again)
   
âŒ FINAL: Marked as "failed" permanently
```

**Total wait time:** ~30 seconds across all retries

---

## ğŸ”„ Resume from Where It Stopped

### **NEW FEATURE: Resumable Downloads**

If a download fails after downloading 60% (e.g., 600 MB of 1 GB):

**Before (Old):**
```
Attempt 1: 0% â†’ 60% âŒ (network drops)
Attempt 2: 0% â†’ 25% âŒ (starts from 0% again!)
Attempt 3: 0% â†’ 80% âŒ (starts from 0% again!)
```
âŒ Wastes bandwidth, starts over each time

**Now (NEW):**
```
Attempt 1: 0% â†’ 60% âŒ (network drops, saves 600 MB)
Attempt 2: 60% â†’ 75% âŒ (resumes from 60%! saves 750 MB)
Attempt 3: 75% â†’ 100% âœ… (resumes from 75%, completes!)
```
âœ… Smart! Continues from where it stopped

---

## ğŸ› ï¸ How Resume Works

### **Technical Implementation:**

1. **Partial File Saved:**
   - Downloaded bytes are saved to disk even if download fails
   - File: `/downloads/users/{userId}/{contentId}_720p.mp4.partial`

2. **Progress Tracked:**
   - Database stores `downloaded_bytes` and `progress`
   - Example: `downloaded_bytes: 629145600` (600 MB)

3. **Resume on Retry:**
   - Worker checks: "How much was already downloaded?"
   - Uses HTTP Range header: `bytes=629145600-`
   - S3 sends only remaining data (400 MB instead of 1 GB)

4. **Append to File:**
   - New data appends to existing partial file
   - When complete, renames to `.mp4`

### **Example:**

```javascript
// Download 1 GB video that keeps failing

Attempt 1:
  - Downloaded: 0 â†’ 600 MB (60%)
  - Network drops
  - Saves: downloaded_bytes = 629145600
  
Attempt 2 (after 2 seconds):
  - Resumes from: 600 MB
  - Downloads: 600 MB â†’ 750 MB (15% more)
  - Network drops again
  - Saves: downloaded_bytes = 786432000
  
Attempt 3 (after 4 seconds):
  - Resumes from: 750 MB
  - Downloads: 750 MB â†’ 1 GB (25% more)
  - âœ… SUCCESS!
  - Total bandwidth used: 1 GB (not 2.35 GB!)
```

---

## ğŸ“ˆ Retry Strategy: Exponential Backoff

**Why not retry immediately?**

If the server/network is overloaded, retrying immediately might fail again. Exponential backoff gives time for recovery.

### **Delay Formula:**

```
Retry N: delay = 2 seconds Ã— 2^(N-1)

Retry 1: 2 Ã— 2^0 = 2 seconds
Retry 2: 2 Ã— 2^1 = 4 seconds
Retry 3: 2 Ã— 2^2 = 8 seconds
Retry 4: 2 Ã— 2^3 = 16 seconds
```

---

## ğŸ¯ When Does It Retry?

### **Automatic Retry Triggers:**

âœ… Network connection lost  
âœ… S3 server timeout  
âœ… AWS throttling errors  
âœ… Temporary server errors (500, 503)  
âœ… DNS resolution failures  
âœ… Connection reset by peer  

### **No Retry (Permanent Failures):**

âŒ File not found on S3 (404)  
âŒ Access denied (403)  
âŒ Invalid credentials  
âŒ Bucket doesn't exist  
âŒ User cancelled download manually  

---

## ğŸ“Š Database Tracking

Every retry updates the database:

```javascript
{
  status: "downloading",       // Current state
  progress: 75,                // 75% complete
  downloaded_bytes: 786432000, // 750 MB downloaded
  failed_count: 2,             // Failed 2 times so far
  error_message: "Network timeout", // Last error
}
```

After 5 attempts fail:

```javascript
{
  status: "failed",            // Permanently failed
  progress: 75,                // Stuck at 75%
  downloaded_bytes: 786432000, // 750 MB downloaded (partial)
  failed_count: 5,             // All retries exhausted
  error_message: "Max retries exceeded: Network timeout",
}
```

User can manually restart to try again.

---

## ğŸ” Monitoring Retries

### **Check Retry Status:**

```bash
GET /api/downloads/{downloadId}/progress

Response:
{
  "id": "download_123",
  "status": "downloading",
  "progress": 65,
  "downloaded_bytes": "681574400",  // 650 MB
  "failed_count": 1,                // Already failed once
  "error_message": "Network timeout",
  "retry_info": {
    "current_attempt": 2,           // On 2nd attempt
    "max_attempts": 5,              // Will retry 3 more times
    "next_retry_in": "4 seconds"    // Next retry soon
  }
}
```

---

## ğŸ§ª Testing Retry Mechanism

### **Simulate Network Failure:**

```bash
# Start download
curl -X POST http://localhost:4000/api/downloads/start \
  -H "Authorization: Bearer TOKEN" \
  -d '{"content_id":"abc123","quality":"720p"}'

# While downloading, disconnect internet for 10 seconds
# Reconnect internet

# Check status - should show retry attempt
curl http://localhost:4000/api/downloads/{id}/progress

# Download should resume and complete!
```

### **Simulate S3 Error:**

```javascript
// Temporarily set wrong S3 credentials in .env
AWS_S3_BUCKET=wrong-bucket-name

// Start download - will fail 5 times with "Bucket not found"
// After 5 attempts, status becomes "failed"
```

---

## ğŸ“ Real-World Example

### **Scenario: User downloading 2 GB movie on unstable WiFi**

```
10:00:00 - Download starts (0%)
10:00:45 - Network drops at 30% (600 MB downloaded)
          â¸ï¸ Paused, saved to disk

10:00:47 - Auto-retry #1 (after 2 seconds)
          â–¶ï¸ Resumes from 30%
10:01:15 - Network drops again at 55% (1.1 GB downloaded)
          â¸ï¸ Paused again

10:01:19 - Auto-retry #2 (after 4 seconds)
          â–¶ï¸ Resumes from 55%
10:02:00 - Network drops at 85% (1.7 GB downloaded)
          â¸ï¸ Paused again

10:02:08 - Auto-retry #3 (after 8 seconds)
          â–¶ï¸ Resumes from 85%
10:02:35 - âœ… Complete! (100%, 2 GB)

Total time: 2 minutes 35 seconds
Total bandwidth: 2 GB (not 5.4 GB if started over!)
Retries used: 3 of 5 available
```

---

## âš™ï¸ Configuration

### **Current Settings:**

| Setting | Value | Description |
|---------|-------|-------------|
| **Max Attempts** | 5 | Total tries (1 + 4 retries) |
| **Initial Delay** | 2 seconds | Wait before 1st retry |
| **Backoff Type** | Exponential | Delays double each time |
| **Resume Support** | âœ… Yes | Continues from last byte |
| **Partial Files** | âœ… Saved | Kept for resume |
| **Manual Retry** | âœ… Yes | User can restart failed downloads |

### **To Change Settings:**

Edit [download.controller.js](modules/Download/download.controller.js):

```javascript
await downloadQueue.add("start", data, {
  attempts: 10,        // Change from 5 to 10 retries
  backoff: {
    type: "exponential",
    delay: 5000,       // Change from 2s to 5s initial delay
  },
});
```

---

## ğŸ“ Summary

âœ… **Automatic retries:** 5 attempts total  
âœ… **Smart delays:** 2s, 4s, 8s, 16s (exponential)  
âœ… **Resume support:** Continues from where it stopped  
âœ… **Bandwidth efficient:** Downloads missing parts only  
âœ… **Progress saved:** Partial files kept between retries  
âœ… **User visibility:** Can see retry count and errors  
âœ… **Manual restart:** Users can retry failed downloads  

ğŸš€ **Your downloads are now resilient to network issues!**
